---
title: "Wilcoxon Rank Sum / Mann-Whitney U Test"
output:
  html_document:
    theme: united
    toc: true
    toc_float: true
css: laurens_styles.css
---

```{r, child="_Global-Options.Rmd"}
```

Learning objectives of this asynchronous lesson:

-   Understanding when to use the Mann-Whitney U test
-   Evaluate whether the underlying assumptions of a Mann-Whitney are present
-   Write an appropriate null hypothesis, apply test appropriately, and interpret the p-value

## Data set

For this set of examples, I will continue to use the sample Cyberville families data created in the t-test page. 

```{r}
data <- read.table(url("https://publish.uwo.ca/~lhornic2/IveyStatistics/Datasets/families.txt"), 
                        header = TRUE)

## suppress scientific notation for ease of reading numbers
options(scipen=99)  

```

Using the same set.seed, I can take the exact same random sample from the population. So that I have them for later, I am going to make the variables for HasChildren and HasCollege. 

```{r}
# Using the same random number seed, I will get the same sample from the population dataset
set.seed(11)  

# create the random sample dataset for analysis
n <- 400   # sample size
select.obs <- sample(1:nrow(data), n) 
study.data <- data[select.obs, ]    

# Create a variable identifying whether or not a family has children
study.data$HasChildren <- 0 # initialize the variable
study.data$HasChildren[ study.data$CHILDREN > 0 ] <- 1 # assign a 1 if CHILDREN >0

# make data subsets
data.NoKids <- study.data$INCOME[study.data$HasChildren == 0]
data.YesKids <- study.data$INCOME[study.data$HasChildren == 1]


# Create a variable identifying whether or not the survey respondent has any college
study.data$HasCollege <- 0 # initialize the variable
study.data$HasCollege[ study.data$EDUCATION >= 40 ] <- 1 # assign a 1 if Any College

# make data subsets
data.NoCollege <- study.data$INCOME[study.data$HasCollege == 0]
data.YesCollege <- study.data$INCOME[study.data$HasCollege == 1]

```

## Mann-Whitney U Test

The Mann-Whitney U Test compares the distributions of two groups answering the question: Do both groups come from the same population distribution?  The null hypothesis is that both groups were sampled from the same population distribution. 

The Mann-Whitney U Test provides a non-parametric alternative to t-test.  

The Mann-Whitney U test only has two assumptions

*   Outcome is a continuous, ordinal, or rank measure (Cannot be binary or un-ordered categorical)      
*   Independent observations: The data need to come from a random sample where each observation is independent of other observations   


### Example 1. 

Continuing the example from the MWU presentation, I will demonstrate the built in R function. 

Recall that we are asking the question, Do the salaries of men and women associate consultants come from the same distribution?

We have data on all the associate consultants in a department: seven men consultants and five women consultants. 

````{r}
# Because of the small sample size, we can hand enter the data
men <- c(120500, 103000, 187800, 156000, 145800, 190800, 162800)
women <- c(104800, 110000, 102400, 187200, 121500)

men
women
````

````{r}
# H0: Men and Women associate consultants come from the same income distribution
wilcox.test(men, women)
````

Observe the p-value is 0.202.
Therefore, we do not reject the null hypothesis that men and women associate consultants come from the same income distribution.


### Example 2. 

In the second example, we will evaluate the question: Do families with and without some college have the same average income?

When we looked at this question before, we saw that the assumptions of a t-test were not well satisfied.  The data were right skewed and one population had a much higher variance than the other. While we can use Welsh's t-test to accommodate heteroskedasticity, combined with the right skewed data, it would be reasonable to be concerned about false findings from a t-test. 

Recall the histogram for each sample and the summary statistics:

```{r, echo=FALSE}
# Histogram of population income

avg.NoCollege <- mean(data.NoCollege)
avg.YesCollege <- mean(data.YesCollege)

## histogram for No College
hist(data.NoCollege, 
     breaks = 15,
     xlim = c(-50000, 250000),
   #  ylim = c(0, 55), 
     yaxt = "n",      # don't print the numbers on the y axis because they aren't meaningful
     freq = FALSE,      # Use density instead of frequency to scale the histogram
     xlab = "Income",
     main = "Histogram of Income, No College",
     las = 1 )  # orients the y-axis labels to read horizontally

abline(v=avg.NoCollege,   # draw a line at the population mean
       col = "blue", 
       lwd = 2,   # lwd is the line width
       lty = 2)   # lty is dashed

# Generate values for the normal distribution curve
x_values <- seq(-50000, max(data.NoCollege), length.out = 300)
y_values <- dnorm(x_values, mean = avg.NoCollege, sd = sd(data.NoCollege))

# Add the normal distribution curve to the histogram
lines(x_values, y_values, col = "red", lwd = 2)

text(x = avg.NoCollege + 5000, 
     y = max(y_values)*1.1, 
     adj = 0,    # positions the text box to the left of the coordinates
     labels = paste0("Average income (No college) = $", 
                     format(avg.NoCollege, nsmall = 2)), 
     col = "blue", 
     cex = 0.85)     # cex is font size


## histogram for At least some College
hist(data.YesCollege, 
     breaks = 15,
     xlim = c(-50000, 250000),
   #  ylim = c(0, 55), 
     yaxt = "n",      # don't print the numbers on the y axis because they aren't meaningful
     freq = FALSE,      # Use density instead of frequency to scale the histogram
     xlab = "Income",
     main = "Histogram of Income, At least some College",
     las = 1 )  # orients the y-axis labels to read horizontally

abline(v=avg.YesCollege,   # draw a line at the population mean
       col = "blue", 
       lwd = 2,   # lwd is the line width
       lty = 2)   # lty is dashed

# Generate values for the normal distribution curve
x_values <- seq(-50000, max(data.YesCollege), length.out = 300)
y_values <- dnorm(x_values, mean = avg.YesCollege, sd = sd(data.YesCollege))

# Add the normal distribution curve to the histogram
lines(x_values, y_values, col = "red", lwd = 2)

text(x = avg.YesCollege + 5000, 
     y = max(y_values)*1.1, 
     adj = 0,    # positions the text box to the left of the coordinates
     labels = paste0("Average income (At least some college) = $", format(avg.YesCollege, nsmall = 2)), 
     col = "blue", 
     cex = 0.85)     # cex is font size


```


```{r, echo=FALSE}

# Calculate the group average income, sd of income, se, and 95% CI
income.byCollege <- t(aggregate(study.data$INCOME ~ study.data$HasCollege, 
                          FUN=function(x) {
                              c(avg = mean(x), 
                                n = length(x), 
                                var = var(x),  
                                sd = sd(x), 
                                se = sd(x)/sqrt(length(x)),
                                lower95 = mean(x) + qnorm(0.025)*sd(x)/sqrt(length(x)), 
                                upper95 = mean(x) + qnorm(0.975)*sd(x)/sqrt(length(x))
                                )
                          }
              ))

income.byCollege

```

Recall the results of the two sided t-test:
```{r}
# Two-sample, two-sided, t-test
# H0: Families with and without some college have the same average income
t.test(study.data$INCOME ~ study.data$HasCollege)   

```

Now, let's compare the results to the MWU:
```{r}
# Two-sided Mann-Whitney U Test
# H0: Families with and without some college have the same distribution of income
wilcox.test(study.data$INCOME ~ study.data$HasCollege)

```

Using the MWU test, the p-value continues to be very very small. 
We reject the null hypothesis that families with and without some college have the same distribution of income. 



### Example 3. 

In the third example, we will evaluate the question: Do families with children have the same average income as families without children?

When we looked at this question before, we did not evaluate the underlying assumptions of a t-test, so we can do that now. 

* First, we know that Income is a continuous outcome
* Second, we know the observations are independent of each other
* Third, we observe that the distribution is quite right skewed.  This is not Normal data and a small number of very high observations may be influencing the sample means in a manner that will alter the outcome of a t-test.  For this reason, I would choose a Mann-Whitney U test over a t-test for these data. 
* Fourth, the standard deviation of the two samples is similar, certainly well within what could be accommodated with a Welsh's correction if all other assumptions were satisfied (but they are not).

```{r, echo=FALSE}
# Histogram of population income

avg.NoKids <- mean(data.NoKids)
avg.YesKids <- mean(data.YesKids)

## histogram for No College
hist(data.NoKids, 
     breaks = 15,
     xlim = c(-50000, 200000),
   #  ylim = c(0, 55), 
     yaxt = "n",      # don't print the numbers on the y axis because they aren't meaningful
     freq = FALSE,      # Use density instead of frequency to scale the histogram
     xlab = "Income",
     main = "Histogram of Income, No Children",
     las = 1 )  # orients the y-axis labels to read horizontally

abline(v=avg.NoKids,   # draw a line at the population mean
       col = "blue", 
       lwd = 2,   # lwd is the line width
       lty = 2)   # lty is dashed

# Generate values for the normal distribution curve
x_values <- seq(-50000, max(data.NoKids), length.out = 300)
y_values <- dnorm(x_values, mean = avg.NoKids, sd = sd(data.NoKids))

# Add the normal distribution curve to the histogram
lines(x_values, y_values, col = "red", lwd = 2)

text(x = avg.NoKids + 7500, 
     y = max(y_values)*1.1, 
     adj = 0,    # positions the text box to the left of the coordinates
     labels = paste0("Average income (No children) = $", 
                     format(avg.NoKids, nsmall = 2)), 
     col = "blue", 
     cex = 0.85)     # cex is font size


## histogram for with Children
hist(data.YesKids, 
     breaks = 15,
     xlim = c(-50000, 200000),
   #  ylim = c(0, 55), 
     yaxt = "n",      # don't print the numbers on the y axis because they aren't meaningful
     freq = FALSE,      # Use density instead of frequency to scale the histogram
     xlab = "Income",
     main = "Histogram of Income, with Children",
     las = 1 )  # orients the y-axis labels to read horizontally

abline(v=avg.YesKids,   # draw a line at the population mean
       col = "blue", 
       lwd = 2,   # lwd is the line width
       lty = 2)   # lty is dashed

# Generate values for the normal distribution curve
x_values <- seq(-50000, max(data.YesKids), length.out = 300)
y_values <- dnorm(x_values, mean = avg.YesKids, sd = sd(data.YesKids))

# Add the normal distribution curve to the histogram
lines(x_values, y_values, col = "red", lwd = 2)

text(x = avg.YesKids + 7500, 
     y = max(y_values)*1.1, 
     adj = 0,    # positions the text box to the left of the coordinates
     labels = paste0("Average income (wtih Children) = $", format(avg.YesKids, nsmall = 2)), 
     col = "blue", 
     cex = 0.85)     # cex is font size


```


```{r, echo=FALSE}

# Calculate the group average income, sd of income, se, and 95% CI
income.byCollege <- t(aggregate(study.data$INCOME ~ study.data$HasChildren, 
                          FUN=function(x) {
                              c(avg = mean(x), 
                                n = length(x), 
                                var = var(x),  
                                sd = sd(x), 
                                se = sd(x)/sqrt(length(x)),
                                lower95 = mean(x) + qnorm(0.025)*sd(x)/sqrt(length(x)), 
                                upper95 = mean(x) + qnorm(0.975)*sd(x)/sqrt(length(x))
                                )
                          }
              ))

income.byCollege

```


Recall the results of the two sided t-test:
```{r}
# Two-sample, two-sided, t-test
# H0: Families with and without some college have the same average income
t.test(study.data$INCOME ~ study.data$HasChildren)   

```

Now, let's compare the results to the MWU:
```{r}
# Two-sided Mann-Whitney U Test
# H0: Families with and without some college have the same distribution of income
wilcox.test(study.data$INCOME ~ study.data$HasChildren)

```

Using the MWU test, the p-value decreases from 0.034 to 0.02. 
We reject the null hypothesis that families with and without children have the same distribution of income. 






## Bootstrapping a null distribution

In the next section, I will demonstrate how to use bootstrapping (read: simulation) to generate the null distribution.  Bootstrapped p-values are common with non-parametric tests (built into the R function for the test). 

### Step 1. Generate the null distribution

In the first step, we will write a function to simulate the possible results of a study with two samples, with sample sizes n1 and n2 respectively, thousands of times. 

```{r}
bootstrap.MWU.p <- function(n1, n2, sims = 5000){
      null.dist <- rep(NA, length = sims)  # initialize a vector to hold results

      for(i in c(1:sims)){
          ## randomly generate random values for samples 1 and 2
          null.samp <- runif(n1+n2)
          
          # assign ranks to the combined dataset where the first n1 will be the ranks for sample 1
          null.ranks <- rank(null.samp)
          
          # Calculate the U value for group 1  (the null distribution is symmetrical, so we only need 1 side)
          U1 <- sum(null.ranks[1:n1]) - n1*(n1+1)/2
          
          null.dist[i] <- U1
      }
      
      # calculate the area under the curve from the left of the null distribution
      cum.freq <- cumsum(table(null.dist)/sims)  
      # Combine the U values with 2-sided p-values; then only print the U values for the left half of the curve
      p.values <- data.frame(U.value = as.numeric(names(cum.freq)), Two.sided.p = cum.freq*2)
      p.values <- p.values[which(p.values$Two.sided.p < 1), ]

      return(p.values)
  }

```

Now let's test our function on an example where we know the solution!

```{r}
## Let's use the null distribution simulator to generate a look up table for our first example

# Generate the p-value table for the first example with n1=5 and n2=7
p.value.table <- bootstrap.MWU.p(5, 7, sims = 10000)

# print the lookup table
p.value.table

# recall that the smaller U was 9
p.value.table$Two.sided.p[p.value.table$U.value == 9]

```

### Step 2. Build a MWU function
We can build our own Mann-Whitney U Test function:

```{r}
MWU <- function(data1, data2, sims = 5000){
          n1 = length(data1)
          n2 = length(data2)
  
          # assign ranks to the combined dataset where the first n1 will be the ranks for sample 1
          ranked <- rank(c(data1, data2))
          
          # Calculate the U values (must do both because we don't know which will be smaller)
          U1 <- sum(ranked[1:n1]) - n1*(n1+1)/2
          U2 <- sum(ranked[(n1+1):(n1+n2)]) - n2*(n2+1)/2
          
          minU <- min(U1, U2)  
      
          # create the null distribution to look up the p-value
          p.value.table <- bootstrap.MWU.p(n1, n2, sims)
          
          # when there are many many possible U values, the precise value might not be in the table... 
          #   so let's pull the closest value
          #   (added an integer control just in case there are ties in the ranks)
          U.position = which.min(abs(p.value.table$U.value - as.integer(minU)))
          p.value.sim <- p.value.table$Two.sided.p[U.position]
          
          # with larger sample sizes, the null distribution for the MWU test 
          #  is asymptotically Normal.
          # This means we can also calculate the p-value using the Normal distribution
          mean.null.U = (n1 * n2)/2
          sd.null.U = sqrt( n1 * n2 * (n1 + n2 + 1) /12 )
          p.value.Norm <- pnorm(minU, mean = mean.null.U, sd = sd.null.U)*2 
          
          # the return statement is what the function prints out
          return(cat("Business Statistics Mann-Whitney two-sided U-test", 
                     "Null hypothesis: Both samples are from the same population distribution",
                       paste("Bootstrapped p-value:", p.value.sim), 
                       paste("Normal distribution p-value:", p.value.Norm),
                       sep = "\n"))

          }

```


### Step 3. Test our new function

Let's compare our own function to the built in function in R

```{r}

wilcox.test(data.NoKids, data.YesKids)

MWU(data.NoKids, data.YesKids, sims = 50000)
```

As you can see our home-made function and the Normal approximation method both replicate the built in R function. 

Note, to calculate a p-value less than 0.0001, it is necessary to complete more than 10,000 simulations.  Similarly, to calculate a p-value less than 0.00001, it is necessary to complete more than 100,000 simulations.  Therefore, the Normal approximation approach will be more accurate for extremely small p values. 

We can test our function again using the more difficult case of the very small p-value. 
```{r}

wilcox.test(data.NoCollege, data.YesCollege)

MWU(data.NoCollege, data.YesCollege, sims = 50000)
```



